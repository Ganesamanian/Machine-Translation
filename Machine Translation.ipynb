{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTyh9NwB-hGa",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical, vis_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, TimeDistributed, RepeatVector, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "RUiXFR8L-_4v",
    "outputId": "a8267068-707b-40c8-fc21-785206050ddb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "      <th>extra information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208476</th>\n",
       "      <td>I recommend contributing sentences in your own...</td>\n",
       "      <td>Ich empfehle, muttersprachliche Sätze beizutra...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208477</th>\n",
       "      <td>A building with high ceilings and huge rooms m...</td>\n",
       "      <td>Ein Gebäude mit hohen Decken und riesigen Räum...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208478</th>\n",
       "      <td>As a prank, some students let three goats loos...</td>\n",
       "      <td>Als Streich ließen einige Schüler drei Ziegen ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208479</th>\n",
       "      <td>In today's world, we have to equip all our kid...</td>\n",
       "      <td>In der heutigen Welt müssen wir all unsere Kin...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208480</th>\n",
       "      <td>Death is something that we're often discourage...</td>\n",
       "      <td>Wir werden oft davon abgehalten, über den Tod ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208481</th>\n",
       "      <td>At a moment when our economy is growing, our b...</td>\n",
       "      <td>In einem Moment, in dem unsere Wirtschaft wäch...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208482</th>\n",
       "      <td>Even if some sentences by non-native speakers ...</td>\n",
       "      <td>Auch wenn Sätze von Nichtmuttersprachlern mitu...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208483</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Wenn jemand, der deine Herkunft nicht kennt, s...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208484</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Wenn jemand Fremdes dir sagt, dass du dich wie...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208485</th>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "      <td>Ohne Zweifel findet sich auf dieser Welt zu je...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       en  \\\n",
       "208476  I recommend contributing sentences in your own...   \n",
       "208477  A building with high ceilings and huge rooms m...   \n",
       "208478  As a prank, some students let three goats loos...   \n",
       "208479  In today's world, we have to equip all our kid...   \n",
       "208480  Death is something that we're often discourage...   \n",
       "208481  At a moment when our economy is growing, our b...   \n",
       "208482  Even if some sentences by non-native speakers ...   \n",
       "208483  If someone who doesn't know your background sa...   \n",
       "208484  If someone who doesn't know your background sa...   \n",
       "208485  Doubtless there exists in this world precisely...   \n",
       "\n",
       "                                                       de  \\\n",
       "208476  Ich empfehle, muttersprachliche Sätze beizutra...   \n",
       "208477  Ein Gebäude mit hohen Decken und riesigen Räum...   \n",
       "208478  Als Streich ließen einige Schüler drei Ziegen ...   \n",
       "208479  In der heutigen Welt müssen wir all unsere Kin...   \n",
       "208480  Wir werden oft davon abgehalten, über den Tod ...   \n",
       "208481  In einem Moment, in dem unsere Wirtschaft wäch...   \n",
       "208482  Auch wenn Sätze von Nichtmuttersprachlern mitu...   \n",
       "208483  Wenn jemand, der deine Herkunft nicht kennt, s...   \n",
       "208484  Wenn jemand Fremdes dir sagt, dass du dich wie...   \n",
       "208485  Ohne Zweifel findet sich auf dieser Welt zu je...   \n",
       "\n",
       "                                        extra information  \n",
       "208476  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "208477  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "208478  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "208479  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "208480  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "208481  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "208482  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "208483  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "208484  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "208485  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading of data from txt file\n",
    "data = pd.read_csv(\"deu-eng/deu.txt\", sep='\\t', names=['en','de', 'extra information'])\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "1RHcLsAh_FFc",
    "outputId": "729578f0-8a10-4662-d6c5-e7dcd7da7e58",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>Thanks for bringing Tom home.</td>\n",
       "      <td>Danke, dass du Tom nach Hause gebracht hast!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>Thanks for bringing Tom home.</td>\n",
       "      <td>Danke, dass Sie Tom nach Hause gebracht haben!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>Thanks for bringing Tom home.</td>\n",
       "      <td>Danke, dass ihr Tom nach Hause gebracht habt!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>Thanks for showing me around.</td>\n",
       "      <td>Danke für die Führung!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>Thanks for the fast response.</td>\n",
       "      <td>Danke für die schnelle Antwort!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Thanks for your quick answer.</td>\n",
       "      <td>Danke für eure schnelle Antwort!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Thanks for your quick answer.</td>\n",
       "      <td>Danke für Ihre schnelle Antwort!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>That article is out of stock.</td>\n",
       "      <td>Dieser Artikel ist nicht vorrätig.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>That bed is very comfortable.</td>\n",
       "      <td>Das Bett ist sehr gemütlich.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>That book had a lot of pages.</td>\n",
       "      <td>Das Buch hatte viele Seiten.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  en  \\\n",
       "99990  Thanks for bringing Tom home.   \n",
       "99991  Thanks for bringing Tom home.   \n",
       "99992  Thanks for bringing Tom home.   \n",
       "99993  Thanks for showing me around.   \n",
       "99994  Thanks for the fast response.   \n",
       "99995  Thanks for your quick answer.   \n",
       "99996  Thanks for your quick answer.   \n",
       "99997  That article is out of stock.   \n",
       "99998  That bed is very comfortable.   \n",
       "99999  That book had a lot of pages.   \n",
       "\n",
       "                                                   de  \n",
       "99990    Danke, dass du Tom nach Hause gebracht hast!  \n",
       "99991  Danke, dass Sie Tom nach Hause gebracht haben!  \n",
       "99992   Danke, dass ihr Tom nach Hause gebracht habt!  \n",
       "99993                          Danke für die Führung!  \n",
       "99994                 Danke für die schnelle Antwort!  \n",
       "99995                Danke für eure schnelle Antwort!  \n",
       "99996                Danke für Ihre schnelle Antwort!  \n",
       "99997              Dieser Artikel ist nicht vorrätig.  \n",
       "99998                    Das Bett ist sehr gemütlich.  \n",
       "99999                    Das Buch hatte viele Seiten.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_de = pd.read_csv(\"de_en_data/train.de\", sep='\\t', names=['de'])\n",
    "# train_en = pd.read_csv(\"de_en_data/train.en\", sep='\\t', names=['en'])\n",
    "# test_de = pd.read_csv(\"de_en_data/test.de\", sep='\\t', names=['de'])\n",
    "# test_en = pd.read_csv(\"de_en_data/test.en\", sep='\\t', names=['en'])\n",
    "\n",
    "# train_data = pd.concat([train_de, train_en], axis=1)\n",
    "# test_data = pd.concat([test_de[:len(test_en)], test_en], axis=1)\n",
    "\n",
    "#Extracting few data\n",
    "data = data.drop(columns=['extra information'])\n",
    "train_data = data.iloc[:100000]\n",
    "train_data.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iV686WW_lpg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the subset from the whole data\n",
    "no_of_samples = int(35000) \n",
    "threshold = int((no_of_samples*0.10)+100)\n",
    "train_de_en = train_data.iloc[:no_of_samples]\n",
    "valid_de_en = train_data.iloc[no_of_samples-threshold:no_of_samples+threshold]\n",
    "test_de_en = train_data.iloc[no_of_samples+threshold:no_of_samples+2*threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnlFQcnfGLbe",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Clearning the data - Lowercase, Change the unicode, removing punctuations\n",
    "# doc = [re.split('\\s+', train_en['en'].iloc[i]) for i in range(len(train_en))]\n",
    "def data_preprocessing(dataframe):\n",
    "\n",
    "    doc = [re.split('\\s+', dataframe.iloc[i]) for i in range(len(dataframe))]\n",
    "\n",
    "    clean_doc = []\n",
    "    for sent in doc:\n",
    "        clean_sent = []\n",
    "        clean_sent_str = ''\n",
    "        for token in sent:\n",
    "            token = token.casefold()\n",
    "            # unicode\n",
    "            token = normalize('NFD',token).encode('ascii', 'ignore')\n",
    "            token = token.decode('UTF-8')\n",
    "            # remove punctuations\n",
    "            token = re.sub('[^\\w|^\\s]', '', token)\n",
    "            if token != '':\n",
    "                clean_sent.append(token)\n",
    "        \n",
    "        clean_sent_str = ' '.join(clean_sent)\n",
    "        clean_doc.append(clean_sent_str)\n",
    "    return clean_doc\n",
    "\n",
    "#Processing the training data\n",
    "train_de_processed = data_preprocessing(train_de_en['de'])\n",
    "train_en_processed = data_preprocessing(train_de_en['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84869rCp-vYC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Processing the validation data\n",
    "valid_de_processed = data_preprocessing(valid_de_en['de'])\n",
    "valid_en_processed = data_preprocessing(valid_de_en['en'])\n",
    "#Processing the test data\n",
    "test_de_processed = data_preprocessing(test_de_en['de'])\n",
    "test_en_processed = data_preprocessing(test_de_en['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0eeF_aZ28g0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenizing\n",
    "def create_tokenizer(data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DMRnrF-OlUoh",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German-the vocab size is 8178, the sentence length 12, number of token 35000\n",
      "English-the vocab size is 5175, the sentence length 6, number of token 35000\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing, getting vocab size and max length of the sentence\n",
    "def get_vocab_size(data):\n",
    "    tokenizer = create_tokenizer(data)\n",
    "    vocab_size = len(tokenizer.word_index)+1\n",
    "    max_length = max(len(sent.split()) for sent in data)\n",
    "    return int(vocab_size), max_length, tokenizer\n",
    "\n",
    "#Getting token, vocab size and max length for both english and german\n",
    "de_vocab_size, de_length, de_tokenizer = get_vocab_size(train_de_processed)\n",
    "en_vocab_size, en_length, en_tokenizer = get_vocab_size(train_en_processed)\n",
    "print(\"German-the vocab size is {}, the sentence length {}, number of token {}\"\\\n",
    "      .format(de_vocab_size, de_length, len(de_tokenizer.texts_to_sequences(train_de_processed))))\n",
    "print(\"English-the vocab size is {}, the sentence length {}, number of token {}\"\\\n",
    "      .format(en_vocab_size, en_length, len(en_tokenizer.texts_to_sequences(train_de_processed))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF0UWkcHrnCI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Padding the data\n",
    "def encode_sequences(tokenizer, length, data):\n",
    "    X = tokenizer.texts_to_sequences(data)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    "\n",
    "#Creating one hot vector for the output\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for seq in sequences:\n",
    "        encode = to_categorical(seq, num_classes=vocab_size)\n",
    "        ylist.append(encode)\n",
    "    y = np.array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    "\n",
    "#Preparing the train data for the neural model\n",
    "trainX = encode_sequences(de_tokenizer, de_length, train_de_processed)\n",
    "trainY = encode_sequences(en_tokenizer, en_length, train_en_processed)\n",
    "trainY = encode_output(trainY, en_vocab_size)\n",
    "\n",
    "#Preparing the validation data for the neural model\n",
    "validX = encode_sequences(de_tokenizer, de_length, valid_de_processed)\n",
    "validY = encode_sequences(en_tokenizer, en_length, valid_en_processed)\n",
    "validY = encode_output(validY, en_vocab_size)\n",
    "\n",
    "#Preparing the test data for the neural model\n",
    "testX = encode_sequences(de_tokenizer, de_length, test_de_processed)\n",
    "testY = encode_sequences(en_tokenizer, en_length, test_en_processed)\n",
    "testY = encode_output(testY, en_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#To cancel the epoch once required accuracy is being reached\n",
    "class myCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.94):\n",
    "            print(\"\\nReached 94% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "colab_type": "code",
    "id": "ROQAzJMx7zQt",
    "outputId": "25b40890-3068-4fdd-a529-05a19488f85d",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 12, 256)           2093568   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 6, 512)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 6, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 6, 5175)           2654775   \n",
      "=================================================================\n",
      "Total params: 7,373,879\n",
      "Trainable params: 7,373,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Creating the Encoder Decoder Model\n",
    "def define_model(de_vocab_size, en_vocab_size, de_length, en_length, n_units):\n",
    "    #Define the model will be stacked linear layers\n",
    "    model = Sequential()\n",
    "    #Creating embedding for the sentence\n",
    "    model.add(Embedding(de_vocab_size, n_units, input_length=de_length, mask_zero=True))\n",
    "    #Creating Bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(n_units)))\n",
    "    #Creating the context vector available every time for the decoder\n",
    "    model.add(RepeatVector(en_length))\n",
    "    #Creating Bidirectional LSTM as a decoder which returns the full sequence   \n",
    "    model.add(Bidirectional(LSTM(n_units, return_sequences=True)))\n",
    "    #Creating a wrapper to get the output in a single time step\n",
    "    model.add(TimeDistributed(Dense(en_vocab_size, activation='softmax')))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = define_model(de_vocab_size, en_vocab_size, de_length, en_length, 256)\n",
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy', 'mse'])\n",
    "#Print the created model structure\n",
    "print(model.summary())\n",
    "# vis_utils.plot_model(model, to_file=\"model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "8R4mvHYGDcE-",
    "outputId": "1dc8109c-1413-4c2c-91e3-d7f451c642cd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ganesh/.local/lib/python3.5/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 7200 samples\n",
      "Epoch 1/30\n",
      " - 82s - loss: 3.4213 - accuracy: 0.4992 - mse: 1.1658e-04 - val_loss: 3.4235 - val_accuracy: 0.4477 - val_mse: 1.2910e-04\n",
      "Epoch 2/30\n",
      " - 77s - loss: 2.3368 - accuracy: 0.6093 - mse: 9.4752e-05 - val_loss: 2.6424 - val_accuracy: 0.5330 - val_mse: 1.1514e-04\n",
      "Epoch 3/30\n",
      " - 77s - loss: 1.7021 - accuracy: 0.6765 - mse: 8.1063e-05 - val_loss: 2.1897 - val_accuracy: 0.5845 - val_mse: 1.0655e-04\n",
      "Epoch 4/30\n",
      " - 78s - loss: 1.2458 - accuracy: 0.7317 - mse: 6.9778e-05 - val_loss: 1.7963 - val_accuracy: 0.6391 - val_mse: 9.3972e-05\n",
      "Epoch 5/30\n",
      " - 77s - loss: 0.9275 - accuracy: 0.7801 - mse: 5.9348e-05 - val_loss: 1.6008 - val_accuracy: 0.6779 - val_mse: 8.7109e-05\n",
      "Epoch 6/30\n",
      " - 78s - loss: 0.7101 - accuracy: 0.8194 - mse: 5.0337e-05 - val_loss: 1.4710 - val_accuracy: 0.7086 - val_mse: 8.0588e-05\n",
      "Epoch 7/30\n"
     ]
    }
   ],
   "source": [
    "fit_data = model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(validX, validY), verbose=2, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.save('MyModel.h5')\n",
    "# loaded_model_h5 = tf.keras.models.load_model('MyModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('MyModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpjqGUXiGffI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# remapping the vector to a word\n",
    "def remap_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeeCNo8XYQGA",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# generate target from given source sequence\n",
    "def predict_sequence(model, tokenizer, input):\n",
    "    prediction = model.predict(input, verbose=0)[0]\n",
    "    integers = [np.argmax(np.array(vector)) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = remap_to_word(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "   \n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4X48fGe_IHvK",
    "outputId": "775abb11-1b1d-4438-91fb-1d3a3d91bc89",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Predict the target (translating from German to English)\n",
    "def predict(model, tokenizer, sources, de_data, en_data):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, tokenizer, source)\n",
    "        if i<10:\n",
    "            print(\"Source is [{}], Target is [{}], Predicted is [{}]\".format(de_data[i], en_data[i], translation))\n",
    "    \n",
    "        actual.append([en_data[i].split()])\n",
    "        predicted.append(translation.split())\n",
    "    return actual, predicted\n",
    " \n",
    "#Evaluate using bleu score\n",
    "def evaluate_model(actual, predicted):\n",
    "    print(\"BLEU-1 is {:.2f}\".format(corpus_bleu(actual, predicted, weights=[1.0, 0.0, 0.0, 0.0])))\n",
    "    print(\"BLEU-2 is {:.2f}\".format(corpus_bleu(actual, predicted, weights=[0.5, 0.5, 0.0, 0.0])))\n",
    "    print(\"BLEU-3 is {:.2f}\".format(corpus_bleu(actual, predicted, weights=[0.3, 0.3, 0.3, 0.0])))\n",
    "    print(\"BLEU-4 is {:.2f}\".format(corpus_bleu(actual, predicted, weights=[0.25, 0.25, 0.25, 0.25])))\n",
    "    \n",
    "\n",
    "\n",
    "actual, predicted = predict(model, en_tokenizer, trainX, train_de_processed, train_en_processed)\n",
    "#evaluate_model(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "1Snmg_umboGu",
    "outputId": "729057a8-012f-4384-8f52-0c58b29be5be",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxYMP-MRb5FF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "test_actual, test_predicted = predict(model, en_tokenizer, testX, test_de_processed, test_en_processed)\n",
    "evaluate_model(test_actual, test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
